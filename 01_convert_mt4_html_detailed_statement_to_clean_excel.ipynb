{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "faa44ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "24961d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths from environment variables\n",
    "base_path = os.getenv('HTML_PATH')\n",
    "download_path = os.getenv('DOWNLOAD_PATH')\n",
    "\n",
    "# Construct full path to HTML file\n",
    "# path = os.path.join(base_path, \"1.htm\")\n",
    "path = os.path.join(base_path, \"DetailedStatement.htm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b058a4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: HTML file not found at C:\\Users\\calli\\Downloads\\PROP-database-new\\da_aggiungere\\fnext\\100\\f\\DetailedStatement.htm\n"
     ]
    }
   ],
   "source": [
    "# Check if file exists before reading\n",
    "if not os.path.exists(path):\n",
    "    print(f\"Error: HTML file not found at {path}\")\n",
    "else:\n",
    "    # Read HTML file\n",
    "    tables = pd.read_html(path)\n",
    "    \n",
    "    # Check if tables are found\n",
    "    if not tables:\n",
    "        print(\"No tables found in the HTML file.\")\n",
    "    else:\n",
    "        print(f\"Found {len(tables)} tables in the HTML file.\")\n",
    "        for i, table in enumerate(tables, 1):\n",
    "            print(f\"Table {i}: {table.shape[0]} rows x {table.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c159bf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot convert: HTML file not found.\n"
     ]
    }
   ],
   "source": [
    "def html_to_excel(html_file, excel_file):\n",
    "    try:\n",
    "        # Read HTML tables from the file\n",
    "        tables = pd.read_html(html_file)\n",
    "        if not tables:\n",
    "            print(\"No tables found in the HTML file.\")\n",
    "            return\n",
    "        \n",
    "        # Save each table to a separate sheet in Excel\n",
    "        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "            for idx, table in enumerate(tables, start=1):\n",
    "                sheet_name = f\"Sheet{idx}\"\n",
    "                table.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        print(f\"Conversion successful!\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{html_file}' not found.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error reading HTML: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "# Convert the HTML file to Excel\n",
    "if os.path.exists(path):\n",
    "    excel_output = os.path.join(download_path, \"converted_tables.xlsx\")\n",
    "    html_to_excel(path, excel_output)\n",
    "else:\n",
    "    print(\"Cannot convert: HTML file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read converted csv file\n",
    "df = pd.read_excel(excel_output, sheet_name='Sheet1')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4493f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"conditions always valid\"\"\"\n",
    "\n",
    "# keep rows from row 2\n",
    "df = df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# RangeIndex have the corrected column names\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "\n",
    "# there are two columns with the same name 'Price'\n",
    "# rename the second 'Price' column to 'Price2'\n",
    "df.columns = df.columns.where(df.columns.duplicated() == False, df.columns + '2')\n",
    "\n",
    "# trim whitespace from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# # trim Profit column values\n",
    "# df['Profit'] = df['Profit'].str.strip()\n",
    "\n",
    "# # replace empty characters with '' in 'Profit' column\n",
    "# df['Profit'] = df['Profit'].replace(r'^\\s*$', '', regex=True)\n",
    "\n",
    "#  drop 'Taxes' column\n",
    "df = df.drop(columns=['Taxes'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe60940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53fd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom df.tail() check first row with SumSummary:\\tSummary:\\tSummary:\\ncancel all rows from that row onwards, indicating the RangeIndex num\\n'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================\n",
    "\"\"\"\n",
    "from df.tail() check first row with SumSummary:\tSummary:\tSummary:\n",
    "cancel all rows from that row onwards, indicating the RangeIndex num\n",
    "\"\"\"\n",
    "# =================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"conditions depending on data, check data length first\"\"\"\n",
    "# drop rows indicating correct RangeIndex (with iloc)\n",
    "up_to_row = 1356  # adjust this number based on actual data\n",
    "df = df.iloc[:up_to_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefa933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"conditions always valid\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "drop rows where 'Open Time' and 'Close Time' have the following values:\n",
    "Closed P/L:\n",
    "Open Trades:\n",
    "Open Time\n",
    "Working Orders:\n",
    "No transactions\n",
    "0.00\n",
    "\"\"\"\n",
    "# drop strings in 'Open Time' and 'Close Time' columns\n",
    "strings_to_drop = ['Closed P/L:', 'Open Trades:', 'Open Time', 'Working Orders:', 'No transactions', '0.00']\n",
    "df = df[~df['Open Time'].isin(strings_to_drop)]\n",
    "df = df[~df['Close Time'].isin(strings_to_drop)]\n",
    "\n",
    "\"\"\"\n",
    "drop rows where 'Type' have the following values:\n",
    "balance\n",
    "\"\"\"\n",
    "# drop strings in 'Type' column\n",
    "df = df[~df['Type'].isin(['balance'])]\n",
    "\n",
    "# drop rows where 'Ticket' is nan\n",
    "df = df.dropna(subset=['Ticket'])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331562f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "drop rows where 'Commission' contains the following values:\n",
    "cancelled\n",
    "Floating P/L:\n",
    "\"from #\"\n",
    "\"Portfolio\"\n",
    "\"folio\"  \n",
    "\"to #\"\n",
    "[tp]\n",
    "[sl]\n",
    "\"\"\"\n",
    "\n",
    "# drop rows where Commission column contains any of these strings\n",
    "strings_to_drop_commission = ['cancelled', 'Floating P/L:', 'from #', 'Portfolio', 'folio', 'to #', '[tp]', '[sl]']\n",
    "\n",
    "# Use str.contains with regex OR pattern to match any of the strings\n",
    "pattern = '|'.join(strings_to_drop_commission)\n",
    "df = df[~df['Commission'].str.contains(pattern, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print df.Commission.unique()\n",
    "# print(df.Commission.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Open Time and Close Time to datetime\n",
    "df['Open Time'] = pd.to_datetime(df['Open Time'])\n",
    "df['Close Time'] = pd.to_datetime(df['Close Time'])\n",
    "\n",
    "# drop rows where 'Open Time' is nan\n",
    "df = df.dropna(subset=['Open Time'])\n",
    "\n",
    "# replace rows where 'Close Time' is nan with 'Close Time' = 'Open Time' + 4 hours\n",
    "df['Close Time'] = df['Close Time'].fillna(df['Open Time'] + pd.Timedelta(hours=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e7190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3778ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2db349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print df.Profit.unique()\n",
    "# print(df.Profit.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean Profit column before converting to float\n",
    "# remove spaces used as thousands separators\n",
    "df['Profit'] = df['Profit'].astype(str).str.replace(' ', '', regex=False)\n",
    "\n",
    "# convert cleaned dataframe to proper Dtypes\n",
    "df = df.astype({\n",
    "    'Size': 'float64',\n",
    "    # check if 'Ticket' can be converted to int, if not use 'str' instead\n",
    "    'Ticket': 'int64',\n",
    "    'S / L': 'float64',\n",
    "    'T / P': 'float64',\n",
    "    'Price': 'float64',\n",
    "    'Price2': 'float64',\n",
    "    'Commission': 'float64',\n",
    "    'Swap': 'float64',\n",
    "    'Profit': 'float64'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22233291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 671 entries, 1 to 1344\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Ticket      671 non-null    int64         \n",
      " 1   Open Time   671 non-null    datetime64[ns]\n",
      " 2   Type        671 non-null    object        \n",
      " 3   Size        671 non-null    float64       \n",
      " 4   Item        671 non-null    object        \n",
      " 5   Price       671 non-null    float64       \n",
      " 6   S / L       671 non-null    float64       \n",
      " 7   T / P       671 non-null    float64       \n",
      " 8   Close Time  671 non-null    datetime64[ns]\n",
      " 9   Price2      671 non-null    float64       \n",
      " 10  Commission  671 non-null    float64       \n",
      " 11  Swap        671 non-null    float64       \n",
      " 12  Profit      671 non-null    float64       \n",
      "dtypes: datetime64[ns](2), float64(8), int64(1), object(2)\n",
      "memory usage: 73.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd853d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame shape: (671, 13)\n",
      "Column names: ['Ticket', 'Open Time', 'Type', 'Size', 'Item', 'Price', 'S / L', 'T / P', 'Close Time', 'Price2', 'Commission', 'Swap', 'Profit']\n"
     ]
    }
   ],
   "source": [
    "# print shape of cleaned dataframe\n",
    "print(f\"Cleaned DataFrame shape: {df.shape}\")\n",
    "\n",
    "# print column names\n",
    "print(\"Column names:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f174d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "\"\"\"\n",
    "rename cleaned dataframe to clean Excel file name in the next cell\n",
    "\"\"\"\n",
    "# =================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download cleaned dataframe to excel\n",
    "cleaned_excel_output = os.path.join(download_path, \"cleaned_excel_output.xlsx\")\n",
    "\n",
    "df.to_excel(cleaned_excel_output, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
